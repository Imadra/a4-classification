{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import random\n",
    "import Perceptron_Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 785\n",
    "out_dim = 10\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    data_file = np.loadtxt(file_name, delimiter=',')\n",
    "    dataset = np.insert(data_file[:, np.arange(1, in_dim)]/255, 0, 1, axis=1)\n",
    "    data_labels = data_file[:, 0]\n",
    "    return dataset, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weight matrix with random weights\n",
    "weight = np.random.uniform(-0.05,0.05,(in_dim,out_dim)) # (785, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Training Set\n",
      "\n",
      "Loading Test Set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Training and Test Sets :\n",
    "print(\"\\nLoading Training Set\")\n",
    "train_data, train_labels = load_data('data/train.csv') # (60000, 785)\n",
    "print(\"\\nLoading Test Set\\n\")\n",
    "test_data, test_labels = load_data('data/test.csv') # (10000, 785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_acc = []\n",
    "arr_test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 1 :\tTraining Set Accuracy = 0.11798333333333333\n",
      "\t\tTest Set Accuracy = 0.1143\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 2 :\tTraining Set Accuracy = 0.8764666666666666\n",
      "\t\tTest Set Accuracy = 0.8764\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 3 :\tTraining Set Accuracy = 0.8952833333333333\n",
      "\t\tTest Set Accuracy = 0.8939\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 4 :\tTraining Set Accuracy = 0.886\n",
      "\t\tTest Set Accuracy = 0.885\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 5 :\tTraining Set Accuracy = 0.8868\n",
      "\t\tTest Set Accuracy = 0.8839\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, num_epochs+1):\n",
    "    \n",
    "    pred_train_labels = Perceptron_Lib.get_predictions(train_data, weight)  # Test network on training set and get training accuracy\n",
    "    print(train_labels.shape)\n",
    "    print(pred_train_labels.shape)\n",
    "    curr_accu = accuracy_score(train_labels, pred_train_labels)\n",
    "\n",
    "    print(\"Epoch \" + str(i) + \" :\\tTraining Set Accuracy = \" + str(curr_accu))\n",
    "\n",
    "    pred_test_labels = Perceptron_Lib.get_predictions(test_data, weight)  # Test network on test set and get accuracy on test set\n",
    "    test_accu = accuracy_score(test_labels, pred_test_labels)\n",
    "    print(\"\\t\\tTest Set Accuracy = \" + str(test_accu))\n",
    "\n",
    "    weight = train(train_data, train_labels, weight)    # Train the network\n",
    "\n",
    "    arr_train_acc.append(curr_accu)\n",
    "    arr_test_acc.append(test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 785 # input dimension\n",
    "out_dim = 10 # number of classes (0-9)\n",
    "eta = 0.01 # Learning rate. You might try different rates (e.g. 0.001, 0.01, 0.1) to maximize the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predictions(dataset, weight_i2o):\n",
    "    # dataset (60000, 785)\n",
    "    # weight_i20 (785, 10)\n",
    "    probabilities = np.dot(dataset, weight_i2o) # probabilities matrix\n",
    "    predictions = np.argmax(probabilities, axis = 1) # output array of indexes with maximum probabilities\n",
    "    return predictions\n",
    "get_predictions(train_data, weight).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_set, labels, weight_i2o):\n",
    "    #\"\"\"\n",
    "    #Train the perceptron until convergence.\n",
    "    # Inputs:\n",
    "        # train_set: training set (ndarray) with shape (number of data points x in_dim)\n",
    "        # labels: list (or ndarray) of actual labels from training set\n",
    "        # weight_i2o:\n",
    "    # Return: the weights for the entire training set\n",
    "    #\"\"\"\n",
    "    for i in range(0, train_set.shape[0]):\n",
    "        weight_i2o = Weight_update(train_set[i, :], labels[i], weight_i2o)\n",
    "    return weight_i2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_update(feature, label, weight_i2o):\n",
    "    predicted_label = np.argmax(np.dot(feature.transpose(), weight_i2o))\n",
    "    if predicted_label == label:\n",
    "        return weight_i2o\n",
    "    else:\n",
    "        tx = np.zeros(10)\n",
    "        tx[int(label)] = 1\n",
    "        yx = np.zeros(10)\n",
    "        yx[predicted_label] = 1\n",
    "        gx = (tx - yx)[np.newaxis]\n",
    "        ff = []\n",
    "        for element in feature:\n",
    "            ff.append([element])\n",
    "        ff = np.array(ff)\n",
    "        new_weight = weight_i2o + eta * ff.dot(gx)\n",
    "        return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 1 :\tTraining Set Accuracy = 0.07911666666666667\n",
      "\t\tTest Set Accuracy = 0.0796\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 2 :\tTraining Set Accuracy = 0.85695\n",
      "\t\tTest Set Accuracy = 0.8562\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 3 :\tTraining Set Accuracy = 0.8828166666666667\n",
      "\t\tTest Set Accuracy = 0.8785\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 4 :\tTraining Set Accuracy = 0.8741166666666667\n",
      "\t\tTest Set Accuracy = 0.868\n",
      "(60000,)\n",
      "(60000,)\n",
      "Epoch 5 :\tTraining Set Accuracy = 0.8644\n",
      "\t\tTest Set Accuracy = 0.8567\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, num_epochs+1):\n",
    "    \n",
    "    pred_train_labels = get_predictions(train_data, weight)  # Test network on training set and get training accuracy\n",
    "    print(train_labels.shape)\n",
    "    print(pred_train_labels.shape)\n",
    "    curr_accu = accuracy_score(train_labels, pred_train_labels)\n",
    "\n",
    "    print(\"Epoch \" + str(i) + \" :\\tTraining Set Accuracy = \" + str(curr_accu))\n",
    "\n",
    "    pred_test_labels = get_predictions(test_data, weight)  # Test network on test set and get accuracy on test set\n",
    "    test_accu = accuracy_score(test_labels, pred_test_labels)\n",
    "    print(\"\\t\\tTest Set Accuracy = \" + str(test_accu))\n",
    "\n",
    "    weight = train(train_data, train_labels, weight)    # Train the network\n",
    "\n",
    "    arr_train_acc.append(curr_accu)\n",
    "    arr_test_acc.append(test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
